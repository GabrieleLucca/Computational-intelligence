{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from itertools import combinations, product\n",
    "from collections import namedtuple, defaultdict\n",
    "from random import choice\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = namedtuple('State', ['x', 'o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC = [2, 7, 6, 9, 5, 1, 4, 3, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def make_move(self, list) -> tuple[int, int]:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._board = np.array([[1, 6, 5], [8, 4, 0], [3, 2, 7]])  # magic board that sum 12\n",
    "        self._o_cells = set()  # start the game  (player_id = 0)\n",
    "        self._x_cells = set()  # play for second (player_id = 1)\n",
    "\n",
    "    def get_state(self) -> tuple[frozenset, frozenset]:\n",
    "        return (frozenset(self._o_cells), frozenset(self._x_cells))\n",
    "\n",
    "    def draw(self) -> bool:\n",
    "        return ((len(self._x_cells) + len(self._o_cells)) == 9) and self.check_winner() == -1\n",
    "\n",
    "    def won(self, cells) -> bool:\n",
    "        return any(sum(h) == 12 for h in combinations(cells, 3))\n",
    "\n",
    "    def check_winner(self) -> int:\n",
    "        if self.won(self._o_cells):\n",
    "            return 0\n",
    "        elif self.won(self._x_cells):\n",
    "            return 1\n",
    "        return -1\n",
    "\n",
    "    def print(self) -> None:\n",
    "        for r in range(self._board.shape[0]):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for c in range(self._board.shape[1]):\n",
    "                if self._board[r, c] in self._x_cells:\n",
    "                   token = 'x'\n",
    "                elif self._board[r, c] in self._o_cells:\n",
    "                    token = 'o'\n",
    "                else:\n",
    "                   token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')\n",
    "\n",
    "    def play(self, player1: Player, player2: Player, QSecond=False) -> int:\n",
    "        game = self\n",
    "        players = [player1, player2]\n",
    "        if QSecond:\n",
    "            current_player_idx = 1\n",
    "        else:\n",
    "            current_player_idx = 0\n",
    "        winner = -1\n",
    "        draw = False\n",
    "        while winner < 0 and not draw:\n",
    "            current_player_idx += 1\n",
    "            current_player_idx %= len(players)\n",
    "            ok = False\n",
    "            while not ok:\n",
    "                pos = players[current_player_idx].make_move(self, game)\n",
    "                ok = self.move(pos, current_player_idx)\n",
    "            winner = self.check_winner()\n",
    "            draw = self.draw()\n",
    "            if True:\n",
    "                self.print()\n",
    "        return winner\n",
    "\n",
    "    def move(self, pos: tuple[int, int], player_id: int) -> bool:\n",
    "        '''Perform a move'''\n",
    "        if player_id > 1:\n",
    "            return False\n",
    "        acceptable: bool = self.valid_move(pos)\n",
    "        if acceptable:\n",
    "            # put the player id in the piece\n",
    "            if player_id == 0:\n",
    "                self._o_cells.add(self._board[pos])\n",
    "            elif player_id == 1:\n",
    "                self._x_cells.add(self._board[pos])\n",
    "        return acceptable\n",
    "    \n",
    "    def valid_move(self, pos: tuple[int, int]) -> bool:\n",
    "        '''Check if the move is valid'''\n",
    "        return self._board[pos] not in (self._x_cells | self._o_cells)\n",
    "    \n",
    "    def get_possible_moves(self):\n",
    "        all_moves = product([0, 1, 2], repeat=2)\n",
    "        legal_moves = []\n",
    "        for move in all_moves:\n",
    "            if self.valid_move(move):\n",
    "                legal_moves.append(move)\n",
    "        return legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPlayer(Player):\n",
    "\n",
    "    def make_move(self, list) -> tuple[int, int]:\n",
    "        # choose random position (row,col)\n",
    "        pos = (random.randint(0, 2), random.randint(0, 2))\n",
    "        return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPlayer(Player):\n",
    "    def __init__(self, learning_rate=0.1, discount_factor=0.9, exploration_prob=0.1):\n",
    "        self.q_values = {}  # Dictionary to store Q-values for state-action pairs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_prob = exploration_prob\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "    def make_move(self, game: Game):\n",
    "        state = game.get_state()\n",
    "        legal_moves = self.get_legal_moves(self, game)\n",
    "\n",
    "        # Choose an action using epsilon-greedy strategy\n",
    "        if np.random.rand() < self.exploration_prob:\n",
    "            action = choice(legal_moves)\n",
    "        else:\n",
    "            action = self.get_best_action(state, legal_moves)\n",
    "\n",
    "        # Store the state-action pair for updating Q-values in the next turn\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_legal_moves(self, game: Game):\n",
    "        # Get legal moves for the current state in the game\n",
    "        legal_moves = [pos for pos in game.get_possible_moves() if game.valid_move(pos)]\n",
    "        return legal_moves\n",
    "\n",
    "    def get_best_action(self, state, legal_moves):\n",
    "        # Choose the best action based on Q-values or a random action if not seen before\n",
    "        if state not in self.q_values:\n",
    "            return choice(legal_moves)\n",
    "        q_values_for_state = self.q_values[state]\n",
    "        best_action = max(legal_moves, key=lambda action: q_values_for_state.get(action, 0))\n",
    "        return best_action\n",
    "\n",
    "    def update_q_values(self, reward, game: Game):\n",
    "        # Update Q-values based on the reward and the transition to the next state\n",
    "        if self.last_state not in self.q_values:\n",
    "            self.q_values[self.last_state] = {}\n",
    "        old_q_value = self.q_values[self.last_state].get(self.last_action, 0)\n",
    "        next_state = game.get_state()\n",
    "        max_next_q_value = max(self.q_values.get(next_state, {}).values(), default=0)\n",
    "        new_q_value = old_q_value + self.learning_rate * (reward + self.discount_factor * max_next_q_value + old_q_value)\n",
    "        self.q_values[self.last_state][self.last_action] = new_q_value\n",
    "    \n",
    "    def training(self) -> None:\n",
    "        # Play multiple episodes/games to train the Q-learning player\n",
    "        num_episodes = 5000\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            # Reset the game for a new episode\n",
    "            game = Game()\n",
    "\n",
    "            while not game.check_winner():\n",
    "                # Make a move using epsilon-greedy strategy\n",
    "                winner = self.make_move(game)\n",
    "\n",
    "            # Apply the selected action and get the reward\n",
    "                if winner == -1:\n",
    "                    # 0 for draw\n",
    "                    reward = 0\n",
    "                elif winner == 0:\n",
    "                    # 10 for win\n",
    "                    reward = 10\n",
    "                else:\n",
    "                    # -10 for lose\n",
    "                    reward = -10\n",
    "\n",
    "            # Update Q-values based on the reward and the transition to the next state\n",
    "            self.update_q_values(reward, game)\n",
    "\n",
    "        print(\"Training completed.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_match(player1, player2):\n",
    "    g = Game()\n",
    "    winner = g.play(player1, player2, QSecond=False)\n",
    "    g.print()\n",
    "    if winner == -1:\n",
    "        print(\"Game endend in Draw.\")\n",
    "    else:\n",
    "        print(f\"Winner: Player {winner}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_match(QPlayer, RandomPlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(player_0, player_1, num_games=1_000):\n",
    "\n",
    "    wins, draws, loses = 0, 0, 0\n",
    "    players = (player_0, player_1)\n",
    "\n",
    "    for _ in range(num_games):\n",
    "        g = Game()\n",
    "\n",
    "        winner = g.play(players)\n",
    "        wins += 1 if winner == 0 else 0\n",
    "        loses += 1 if winner == 1 else 0\n",
    "        draws += 1 if winner == -1 else 0\n",
    "\n",
    "    f'{player_0.__name__} playing as first\\nWins:{wins}\\nLoses:{loses}\\nDraws:{draws}\\nPercentage not loses:{(wins+draws)/num_games:0.2%}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Game()\n",
    "qlplayer = QPlayer()\n",
    "rewards = qlplayer.training(g)\n",
    "test(qlplayer, RandomPlayer())\n",
    "print()\n",
    "test(qlplayer, RandomPlayer(), reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-P-7LqQ3C-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
